# 학습자료
[학습 테스트로 배워보는 kafka](https://wonit.tistory.com/657)
[Kafka의 기본 구조 이해하기](https://curiousjinan.tistory.com/entry/understanding-kafka-all-structure)

# Kafka의 개요
- 실시간 데이터 스트리밍 처리
- 기존 복잡한 아키텍처 피로감
  1. 거짓된 데이터
    - user side에서 생성된 데이터가 여러 시스템 컴포넌트를 거치며 재가공됨.
    - 이로 인해 시스템 이곳저곳에 서로 다른 정보가 사용됨.
    - 시간이 흐르며 데이터 본연의 의미를 보존하고 증명하는 무언가가 필요.
    - 이를 `단일 진실 공급원이 필요`하다고 표현.
  2. 실시간 트랜잭션에 의한 성능 저하
    - 영속화 과정에서 안전한 연산을 위해 hold and wait 방식 사용.
    - 이 경우, 특정 데이터 점유가 발생하며 대기 지연이 발생.
    - 이런 실시간 트랜잭션(OLTP)가 동기적으로 발생하기 때문에 문제가 됨.
    - 이런 동기 방식 트랜잭션을 업애고 비동기 방식의 처리 프로세스를 지원하기 위한 메시징 인프라가 필요.
  3. 준수하지 못한 메시징 시스템의 성능
    - 1,2번 문제를 해결하기 위해 메시징 인프라는 중간에서 message exchage가 실제 메시지를 교환하도록 함.
    - 이 경우, 신뢰성이 중요하기 때문에 메시징 시스템에 대한 책임과 부하가 커지게 됨.

- Kafka의 등장
  - 중앙 집중형 메시징 인프라
  - 로그 지향 아키텍처
    - 다른 메시징 인프라와 다르게, 메시지를 전부 저장.
  - 고가용성, 고확장성
    - `zookeeper`라는 분산 코디네이터와 함께 동작
    - 분산된 카프카 인스턴스들을 클러스터링 하기에, zero downtime을 지원하여 scaling이 가능.
    - producer, consumer로 분리

# Kafka 컨셉
![핵심 요소](image/arch.png)
![카프카 구조](image/cluster.png)

- Cluster
  - 여러 대의 Broker로 구성된 Kafka 시스템
  - 대량 데이터를 처리하고, 여러 Consumer와 Producer에게 메시지 서비스 제공
  - 여러 Broker에 분산시켜 메시지를 저장
- Broker
  - 핵심 구성요소
  - Kafka로 들어오는 이벤트 데이터의 스토리지 서버
  - Topic, Partition, Replication 등을 관리
- Topic
  - 이벤트의 카테고리
  - 이벤트가 저장되는 단위
  - Producer와 Consumer가 바라보는 기본적인 단위
- Producer
  - Topic에 메시지 생산
  - 특정 Partition에도 생산 가능
- Consumer
  - Topic의 메시지 소비
  - 특정 Partition에도 소비 가능
- Partition
  - Topic에 존재하는 실제 메시지 저장소

## Broker

### Kafka Cluster가 연결하는 방법
![cluster connection](image/broker.png)
- Kafka Cluster에 있는 특정 브로커가 bootstrap server를 수행하여 다른 브로커와 연결..

### Kafka의 Bootstrap Server
1. **Bootstrap의 의미**
> 시스템이나 프로그램이 최초로 실행될 때 필요한 최소한의 초기 데이터나 설정, 또는 초기화 과정 자체를 의미.

2. **Kafka에서의 Bootstrap Server 역할**
- Kafka 클라이언트(Producer/Consumer)가 Kafka Cluster와 통신하려면, Cluster의 메타데이터를 알아야 함.
- 이 메타데이터에는 어떤 Broker들이 현재 Cluster에 참여하고 있는지, 내가 원하는 Topic의 Partition이 어느 Broker에 저장되어 있는지 등 핵심 정보가 포함됨.
  
- Kafka는 Bootstrap Server로서 이런 메타데이터를 얻기 위해 아래 역할을 수행
  - 최초 연결 시도: 처음 접속 시, 설정 파일에 지정된 하나 이상의 브로커 주소를 사용. (이 주소들을 bootstrap servers라고 부름)
  - 메타데이터 요청: 클라이언트는 이 bootstrap server 중 하나에 접속 시도.
  - 정보 획득: 연결된 Broker는 클라이언트에게 Cluster 전체의 최신 메타데이터를 응답으로 보내줌.

3. **모든 Broker가 Bootstrap Server**
> 클러스터에 존재하는 모든 브로커 하나 하나가 다른 클러스터의 대표 브로커가 될 수 있다.

- 모든 Broker가 동등하게 메타데이터를 가져올 수 있음.
- 클라이언트가 설정 파일에 브로커 A를 bootstrap server로 지정했다고 하더라도, 브로커 A에 장애가 발생하면 다른 브로커에 접속을 시도하여 메타데이터를 가져올 수 있음.
- 어떤 브로커든 연결하여 메타데이터를 받게 되면, 클라이언트는 그 이후부터 클러스터 내 다른 브로커들과 직접 통신


### Topic
- 카테고리
- Kafka로 들어오는 모든 이벤트들을 Topic이라는 단위로 카테고리화하여 저장함.
- Append Only, 수정 불가능
- **Producer와 Consumer가 여러개 일 수 있음**

### Producer
- Topic에 이벤트 전송
- 원한다면 특정 Topic 내의 Partition에도 메시지 발행 가능

### Consumer
- 이벤트 소비
- `Offset`으로 어떤 Topic에서 이벤트를 읽었고, 어디까지 읽었는지를 관리
  - 순차적으로 증가핮지만, 특정 위치로부터 데이터 소비 가능

### Partition
- 이벤트 발행 시, Topic 내부에 있는 특정 Partition에 저장됨
- 하나의 Topic 내에 여러 개의 Partition을 만들어 처리량을 늘림

### Replication (Topic Replication)
- 고가용성과 고확장성의 핵심 요소
- 모든 Topic을 복제하여 장애에 대한 내결함을 갖음
- 실제 데이터가 Broker에 들어오면, 어느 한 Topic에 데이터가 쌓인다면 Replication에 의해 복제본 Topic에 같이 쌓임

# Zookeeper
- 주키퍼는 브로커 리스트를 관리한다.
- 주키퍼는 파티션들의 리더 선출에 도움을 준다.
- 주키퍼는 변경 시 카프카에게 알림을 보낸다 (new topic, broker dies, broker comes up, delete topics, etc...)
- 카프카 2.x는 무조건 주키퍼로 돌아간다.
- 카프카 3.x부턴 Kafka Raft가 도입되어 주키퍼 없이도 돌아간다.
- 카프카 4.x 부턴 주키퍼가 없다.
- 주키퍼는 카프카보다 보안적으로 떨어지기 때문에 deprecated됐다.

# Kafka Raft
- 주키퍼 사용 시, 파티션이 100,000개를 넘게 되면 스케일링 문제가 발생한다.
- 하지만 주키퍼를 제거함으로 수백만 개의 파티션으로 확장이 가능해짐.
